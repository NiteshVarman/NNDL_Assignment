{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e43750c8-8fdf-45f6-b9d1-e613f2a833f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OR Gate:\n",
      "0 OR 0 = 0\n",
      "0 OR 1 = 1\n",
      "1 OR 0 = 1\n",
      "1 OR 1 = 1\n"
     ]
    }
   ],
   "source": [
    "def step_activation(x):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "def perceptron_or(x1, x2):\n",
    "    w1, w2 = 1, 1\n",
    "    bias = -0.5\n",
    "    y = w1 * x1 + w2 * x2 + bias\n",
    "    return step_activation(y)\n",
    "\n",
    "print(\"OR Gate:\")\n",
    "for x1 in [0, 1]:\n",
    "    for x2 in [0, 1]:\n",
    "        print(f\"{x1} OR {x2} = {perceptron_or(x1, x2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ed02f26-4c3c-442b-984d-de745039348d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "AND Gate:\n",
      "0 AND 0 = 0\n",
      "0 AND 1 = 0\n",
      "1 AND 0 = 0\n",
      "1 AND 1 = 1\n"
     ]
    }
   ],
   "source": [
    "def step_activation(x):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "def perceptron_and(x1, x2):\n",
    "    w1, w2 = 1, 1\n",
    "    bias = -1.5\n",
    "    y = w1 * x1 + w2 * x2 + bias\n",
    "    return step_activation(y)\n",
    "\n",
    "print(\"\\nAND Gate:\")\n",
    "for x1 in [0, 1]:\n",
    "    for x2 in [0, 1]:\n",
    "        print(f\"{x1} AND {x2} = {perceptron_and(x1, x2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8022b5d-2531-49c7-83fd-ea8024085853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XOR Gate:\n",
      "0 XOR 0 = 0\n",
      "0 XOR 1 = 1\n",
      "1 XOR 0 = 1\n",
      "1 XOR 1 = 0\n"
     ]
    }
   ],
   "source": [
    "def step_activation(x):\n",
    "    return 1 if x >= 0 else 0\n",
    "\n",
    "# Hidden neurons\n",
    "def hidden_or(x1, x2):\n",
    "    w1, w2, bias = 1, 1, -0.5\n",
    "    y = w1 * x1 + w2 * x2 + bias\n",
    "    return step_activation(y)\n",
    "\n",
    "def hidden_nand(x1, x2):\n",
    "    w1, w2, bias = -2, -2, 3\n",
    "    y = w1 * x1 + w2 * x2 + bias\n",
    "    return step_activation(y)\n",
    "\n",
    "# Final XOR output using outputs from hidden layer\n",
    "def perceptron_xor(x1, x2):\n",
    "    h1 = hidden_or(x1, x2)\n",
    "    h2 = hidden_nand(x1, x2)\n",
    "\n",
    "    # Output neuron simulates AND gate\n",
    "    w1, w2, bias = 1, 1, -1.5\n",
    "    y = w1 * h1 + w2 * h2 + bias\n",
    "    return step_activation(y)\n",
    "\n",
    "print(\"\\nXOR Gate:\")\n",
    "for x1 in [0, 1]:\n",
    "    for x2 in [0, 1]:\n",
    "        print(f\"{x1} XOR {x2} = {perceptron_xor(x1, x2)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0773d1-8743-457f-a629-aa317b8ab0bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
